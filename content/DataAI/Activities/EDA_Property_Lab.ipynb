{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f8c621c",
   "metadata": {},
   "source": [
    "# üß™ Laboratoire: EDA ‚Üí Nettoyage ‚Üí Mod√©lisation (propri√©t√©)\n",
    "        \n",
    "**Objectifs p√©dagogiques**\n",
    "- Charger et explorer un jeu de donn√©es r√©el (`property.csv`).\n",
    "- √âvaluer la qualit√© des donn√©es (types, valeurs manquantes, doublons, outliers).\n",
    "- Nettoyer et pr√©traiter (imputation, encodage, normalisation).\n",
    "- Entra√Æner et comparer plusieurs mod√®les de r√©gression.\n",
    "- Interpr√©ter les r√©sultats et sauvegarder les artefacts.\n",
    "\n",
    "**Contexte**\n",
    "On suppose que l'on souhaite **pr√©dire un prix** (ex.: `SalePrice`, `Price`, etc.). Si la colonne cible s‚Äôappelle diff√©remment, ajustez `TARGET_COL` ci-dessous.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242c4220",
   "metadata": {},
   "source": [
    "## 1) Imports & configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adc2887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports standards\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Pour l'affichage complet des colonnes\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "# Fichier source (d√©j√† charg√© sur la plateforme)\n",
    "CSV_PATH = '/mnt/data/property.csv'\n",
    "\n",
    "# Si vous connaissez d√©j√† la cible, mettez-la ici. Sinon laissez None pour inf√©rence automatique.\n",
    "TARGET_COL = None  # Exemple: 'SalePrice' ou 'Price'\n",
    "\n",
    "# Utiliser un style par d√©faut (ne PAS fixer de couleurs selon les consignes)\n",
    "# plt.style.use('default')  # d√©j√† par d√©faut\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37d4a16",
   "metadata": {},
   "source": [
    "## 2) Chargement des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33f169e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(CSV_PATH), f'Fichier introuvable: {CSV_PATH}'\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3c23d6",
   "metadata": {},
   "source": [
    "## 3) Structure, types et valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1c8d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nombre de lignes:\", len(df))\n",
    "print(\"Nombre de colonnes:\", df.shape[1])\n",
    "print(\"\\nTypes de donn√©es:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "missing = df.isna().sum().sort_values(ascending=False)\n",
    "missing_pct = (df.isna().mean()*100).sort_values(ascending=False)\n",
    "display(pd.DataFrame({'missing_count': missing, 'missing_pct': missing_pct}).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e177830",
   "metadata": {},
   "source": [
    "## 4) D√©finir la colonne cible (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24079d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heuristique pour inf√©rer la cible si non fournie\n",
    "if TARGET_COL is None:\n",
    "    candidates = [c for c in df.columns if 'price' in c.lower()] or df.select_dtypes(include=[np.number]).columns.tolist()[-1:]\n",
    "    TARGET_COL = candidates[0] if candidates else None\n",
    "\n",
    "print(\"Colonne cible candidate:\", TARGET_COL)\n",
    "assert TARGET_COL is not None, \"Impossible d'inf√©rer la colonne cible. Sp√©cifiez TARGET_COL manuellement.\"\n",
    "\n",
    "# Convertir la cible en num√©rique si n√©cessaire et drop les NA cible\n",
    "df[TARGET_COL] = pd.to_numeric(df[TARGET_COL], errors='coerce')\n",
    "df = df[~df[TARGET_COL].isna()].copy()\n",
    "print(\"Taille apr√®s suppression des NA sur la cible:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618967d1",
   "metadata": {},
   "source": [
    "## 5) Statistiques descriptives et visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13670dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = [c for c in df.columns if c not in numeric_cols]\n",
    "\n",
    "# Stats num√©riques\n",
    "desc = df[numeric_cols].describe().T\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea21edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution de la cible\n",
    "plt.figure()\n",
    "df[TARGET_COL].hist(bins=30)\n",
    "plt.title(f\"Distribution de la cible: {TARGET_COL}\")\n",
    "plt.xlabel(TARGET_COL)\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14786d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributions de quelques variables num√©riques\n",
    "for c in numeric_cols[:6]:\n",
    "    plt.figure()\n",
    "    df[c].hist(bins=30)\n",
    "    plt.title(f\"Distribution: {c}\")\n",
    "    plt.xlabel(c)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ad148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carte de corr√©lation (limiter √† 20 colonnes pour la lisibilit√©)\n",
    "corr_cols = numeric_cols[:20]\n",
    "if len(corr_cols) >= 2:\n",
    "    corr = df[corr_cols].corr(numeric_only=True)\n",
    "    plt.figure()\n",
    "    plt.imshow(corr, aspect='auto')\n",
    "    plt.xticks(range(len(corr_cols)), corr_cols, rotation=90)\n",
    "    plt.yticks(range(len(corr_cols)), corr_cols)\n",
    "    plt.title(\"Heatmap des corr√©lations\")\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139c1eaf",
   "metadata": {},
   "source": [
    "## 6) Qualit√© des donn√©es: doublons, outliers, imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce512df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Doublons\n",
    "before = len(df)\n",
    "df = df.drop_duplicates()\n",
    "print(\"Doublons supprim√©s:\", before - len(df))\n",
    "\n",
    "# b) Winsorization IQR simple pour limiter l'impact des outliers\n",
    "def winsorize_iqr(s, factor=1.5):\n",
    "    q1 = s.quantile(0.25)\n",
    "    q3 = s.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - factor*iqr\n",
    "    upper = q3 + factor*iqr\n",
    "    return s.clip(lower, upper)\n",
    "\n",
    "for c in numeric_cols:\n",
    "    if c == TARGET_COL:\n",
    "        continue\n",
    "    df[c] = winsorize_iqr(df[c])\n",
    "\n",
    "# c) Imputation: num -> m√©diane ; cat -> mode\n",
    "for c in numeric_cols:\n",
    "    df[c] = df[c].fillna(df[c].median())\n",
    "\n",
    "for c in categorical_cols:\n",
    "    if df[c].isna().any():\n",
    "        mode_val = df[c].mode(dropna=True)\n",
    "        mode_val = mode_val.iloc[0] if not mode_val.empty else \"Unknown\"\n",
    "        df[c] = df[c].fillna(mode_val)\n",
    "\n",
    "print(\"Taille finale (post-nettoyage):\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c813a5b4",
   "metadata": {},
   "source": [
    "## 7) (Optionnel) Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4516fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple (adapter selon le dataset)\n",
    "# if 'year_built' in df.columns and 'year_sold' in df.columns:\n",
    "#     df['house_age_at_sale'] = df['year_sold'] - df['year_built']\n",
    "\n",
    "# if 'lot_area' in df.columns and 'living_area' in df.columns:\n",
    "#     df['area_ratio'] = df['living_area'] / (df['lot_area'] + 1e-6)\n",
    "\n",
    "print(\"Colonnes disponibles apr√®s FE (si appliqu√©):\", df.columns.tolist()[:20], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50872c1",
   "metadata": {},
   "source": [
    "## 8) Split & preprocessing (ColumnTransformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905e0293",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [c for c in df.columns if c != TARGET_COL]\n",
    "X = df[feature_cols].copy()\n",
    "y = df[TARGET_COL].copy()\n",
    "\n",
    "X_num = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "X_cat = [c for c in X.columns if c not in X_num]\n",
    "\n",
    "num_tf = Pipeline(steps=[(\"scaler\", StandardScaler(with_mean=False))])\n",
    "cat_tf = Pipeline(steps=[(\"onehot\", OneHotEncoder(handle_unknown='ignore', sparse=True))])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[('num', num_tf, X_num), ('cat', cat_tf, X_cat)],\n",
    "    remainder='drop',\n",
    "    sparse_threshold=0.3\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f77f74",
   "metadata": {},
   "source": [
    "## 9) Entra√Æner plusieurs mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c810b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(alpha=1.0, random_state=42),\n",
    "    \"Lasso\": Lasso(alpha=0.001, max_iter=10000, random_state=42),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(random_state=42),\n",
    "}\n",
    "\n",
    "results = []\n",
    "fitted = {}\n",
    "\n",
    "for name, est in models.items():\n",
    "    pipe = Pipeline(steps=[('preprocess', preprocess), ('model', est)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    fitted[name] = pipe\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    results.append({'model': name, 'MAE': mae, 'RMSE': rmse, 'R2': r2})\n",
    "\n",
    "pd.DataFrame(results).sort_values('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac38bc2",
   "metadata": {},
   "source": [
    "## 10) Interpr√©tation: importances / coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359076bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_names_from_preprocessor(preproc: ColumnTransformer) -> List[str]:\n",
    "    names = []\n",
    "    for name, trans, cols in preproc.transformers_:\n",
    "        if name == 'num':\n",
    "            names.extend(list(cols))\n",
    "        elif name == 'cat':\n",
    "            ohe = trans.named_steps['onehot']\n",
    "            names.extend(ohe.get_feature_names_out(cols).tolist())\n",
    "    return names\n",
    "\n",
    "best_name = pd.DataFrame(results).sort_values('RMSE').iloc[0]['model']\n",
    "best_pipe = fitted[best_name]\n",
    "print(\"Meilleur mod√®le:\", best_name)\n",
    "\n",
    "names = feature_names_from_preprocessor(best_pipe.named_steps['preprocess'])\n",
    "model = best_pipe.named_steps['model']\n",
    "\n",
    "importances_df = None\n",
    "if hasattr(model, 'feature_importances_'):\n",
    "    importances_df = pd.DataFrame({'feature': names, 'importance': model.feature_importances_})                         .sort_values('importance', ascending=False).head(25)\n",
    "elif hasattr(model, 'coef_'):\n",
    "    coef = model.coef_\n",
    "    if hasattr(coef, 'toarray'):\n",
    "        coef = coef.toarray().ravel()\n",
    "    importances_df = pd.DataFrame({'feature': names, 'coefficient': coef})\n",
    "    importances_df['abs_coef'] = importances_df['coefficient'].abs()\n",
    "    importances_df = importances_df.sort_values('abs_coef', ascending=False).drop(columns=['abs_coef']).head(25)\n",
    "\n",
    "importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b750c44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation (barres horizontales) ‚Äî une figure par graphique, couleurs par d√©faut\n",
    "if importances_df is not None:\n",
    "    plt.figure()\n",
    "    col = 'importance' if 'importance' in importances_df.columns else 'coefficient'\n",
    "    vals = importances_df[col].values\n",
    "    labels = importances_df['feature'].values\n",
    "    plt.barh(range(len(vals)), vals)\n",
    "    plt.yticks(range(len(vals)), labels)\n",
    "    plt.title(f\"Top features / coefficients ‚Äî {best_name}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c132e3",
   "metadata": {},
   "source": [
    "## 11) Sauvegarder les artefacts (donn√©es, m√©triques, mod√®le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2c38c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_path = '/mnt/data/property_cleaned_lab.csv'\n",
    "metrics_path = '/mnt/data/model_metrics_lab.csv'\n",
    "model_path = f'/mnt/data/best_model_{best_name}_lab.pkl'\n",
    "\n",
    "# Sauvegarder donn√©es nettoy√©es\n",
    "df.to_csv(clean_path, index=False)\n",
    "\n",
    "# Sauvegarder m√©triques: reprendre results\n",
    "metrics_df = pd.DataFrame(results).sort_values('RMSE')\n",
    "metrics_df.to_csv(metrics_path, index=False)\n",
    "\n",
    "# Sauvegarder le pipeline entra√Æn√©\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump({'pipeline': best_pipe, 'target': TARGET_COL, 'feature_cols': X.columns.tolist()}, f)\n",
    "\n",
    "print('Artifacts:')\n",
    "print(' - Donn√©es nettoy√©es :', clean_path)\n",
    "print(' - M√©triques         :', metrics_path)\n",
    "print(' - Mod√®le            :', model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbfa462",
   "metadata": {},
   "source": [
    "## 12) Questions de r√©flexion (√† discuter en classe)\n",
    "1. Quelles colonnes semblent le plus corr√©l√©es √† la cible ? Pourquoi ?  \n",
    "2. L'IQR capping (winsorization) a-t-il chang√© significativement les distributions ?  \n",
    "3. Quel mod√®le performe le mieux et pourquoi pensez-vous que c'est le cas sur ce dataset ?  \n",
    "4. Que feriez-vous pour am√©liorer la performance (features, hyperparam√®tres, CV) ?  \n",
    "5. Si vous d√©ployiez ce mod√®le, quelles consid√©rations de **biais/√©thique** ou de **vie priv√©e** seraient pertinentes ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
